# ------------------------------------------------------------
# Bitnami Kafka Helm values (single-node KRaft + Connect, PLAINTEXT only)
# ------------------------------------------------------------
replicaCount: 1

# 1) Turn off ZooKeeper; use KRaft instead
zookeeper:
  enabled: false

# 1.a) Disable SASL/SCRAM entirely
auth:
  enabled: false

kraft:
  bootstrapScramUsers: false

# ── Controller + Broker Settings ────────────────────────────────
controller:
  # Single node acts as both controller + broker
  replicaCount: 1
  controllerOnly: false

# ── Listeners (all pure PLAINTEXT) ──────────────────────────────
listeners:
  client:
    protocol: PLAINTEXT
    containerPort: 9092
  controller:
    protocol: PLAINTEXT
    containerPort: 9093
  interbroker:
    protocol: PLAINTEXT
    containerPort: 9094

# Which listener name to use for inter-broker traffic
interBrokerListenerName: INTERNAL

advertisedListeners:
  client:
    protocol: PLAINTEXT
    host: "kafka.kafka-stack.svc.cluster.local"
    port: 9092
    tls: false

listenerSecurityProtocolMap:
  CONTROLLER: PLAINTEXT
  INTERNAL:   PLAINTEXT
  CLIENT:     PLAINTEXT

# ── Internal topic/log settings ───────────────────────────────────
# (No overrideConfiguration block—let Kafka use its chart defaults for internal‐topic creation.)
# If you need auto‐create topics, the chart’s default is already “true” for a new install.
num.partitions:                        "1"
auto.create.topics.enable:             "true"
offsets.topic.replication.factor:      "1"
transaction.state.log.replication.factor: "1"
transaction.state.log.min.isr:         "1"
log.dirs:                              "/opt/bitnami/kafka/data"

# ── We do not run any separate broker-only pods; this single node does both roles ───
broker:
  replicaCount: 0

# ── Persistence (8Gi gp3) ───────────────────────────────────────────
persistence:
  enabled: true
  storageClass: "gp3"
  size: 8Gi

resources:
  requests:
    cpu:    "250m"
    memory: "512Mi"
  limits:
    cpu:    "500m"
    memory: "1Gi"

service:
  type: ClusterIP
  ports:
    client:      9092
    controller:  9093
    interbroker: 9094

metrics:
  kafka:
    enabled: false

extraDeploy:
  # ────────────────────────────────────────────
  # 1) ConfigMap containing connect‐distributed.properties
  # ────────────────────────────────────────────
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: kafka-connect-config
      labels:
        app.kubernetes.io/component: connector
    data:
      connect-distributed.properties: |-
        bootstrap.servers=kafka.kafka-stack.svc.cluster.local:9092
        group.id=connect-cluster

        # ── Converters ──
        key.converter=org.apache.kafka.connect.json.JsonConverter
        value.converter=org.apache.kafka.connect.json.JsonConverter
        key.converter.schemas.enable=false
        value.converter.schemas.enable=false

        # ── Internal storage topics ──
        config.storage.topic=connect-configs
        offset.storage.topic=connect-offsets
        status.storage.topic=connect-status
        config.storage.replication.factor=1
        offset.storage.replication.factor=1
        status.storage.replication.factor=1

        # ── Plugin path (MongoDB connector JAR lives here) ──
        plugin.path=/opt/bitnami/kafka/plugins

  # ────────────────────────────────────────────
  # 2) Deployment for Kafka Connect (with an initContainer that pre‐creates topics)
  # ────────────────────────────────────────────
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: kafka-connect
      labels:
        app.kubernetes.io/component: connector
    spec:
      replicas: 1
      selector:
        matchLabels:
          app.kubernetes.io/component: connector
      template:
        metadata:
          labels:
            app.kubernetes.io/component: connector
        spec:
          # ── INIT CONTAINER: create internal topics if they don't exist ──
          initContainers:
            - name: init-create-connect-topics
              image: docker.io/bitnami/kafka:4.0.0-debian-12-r7
              imagePullPolicy: IfNotPresent
              command:
                - /bin/bash
                - -ec
                - |
                  # Wait for Kafka to be reachable:
                  for i in $(seq 1 15); do
                    kafka-broker-api-versions.sh --bootstrap-server kafka.kafka-stack.svc.cluster.local:9092 &>/dev/null && break
                    echo "Waiting for Kafka..."
                    sleep 2
                  done

                  # 1) __consumer_offsets: (KRaft expects this pre-created if auto.create.internal.topics=false)
                  kafka-topics.sh \
                    --bootstrap-server kafka.kafka-stack.svc.cluster.local:9092 \
                    --if-not-exists \
                    --create \
                    --topic __consumer_offsets \
                    --replication-factor 1 \
                    --partitions 1

                  # 2) connect-offsets
                  kafka-topics.sh \
                    --bootstrap-server kafka.kafka-stack.svc.cluster.local:9092 \
                    --if-not-exists \
                    --create \
                    --topic connect-offsets \
                    --replication-factor 1 \
                    --partitions 1

                  # 3) connect-configs
                  kafka-topics.sh \
                    --bootstrap-server kafka.kafka-stack.svc.cluster.local:9092 \
                    --if-not-exists \
                    --create \
                    --topic connect-configs \
                    --replication-factor 1 \
                    --partitions 1

                  # 4) connect-status
                  kafka-topics.sh \
                    --bootstrap-server kafka.kafka-stack.svc.cluster.local:9092 \
                    --if-not-exists \
                    --create \
                    --topic connect-status \
                    --replication-factor 1 \
                    --partitions 1

          # ── MAIN CONNECT CONTAINER ──
          containers:
            - name: connect
              image: barrype/kafka-connector:1.10.1
              imagePullPolicy: Always

              env:
                - name: KAFKA_HEAP_OPTS
                  value: "-Xms512m -Xmx1g"
              ports:
                - name: rest
                  containerPort: 8083

              # Mount the ConfigMap so that
              # /opt/bitnami/kafka/config/connect-distributed.properties exists:
              volumeMounts:
                - name: configuration
                  mountPath: /opt/bitnami/kafka/config/connect-distributed.properties
                  subPath: connect-distributed.properties

              # Start Connect in distributed mode pointing at that file:
              command:
                - "/opt/bitnami/kafka/bin/connect-distributed.sh"
              args:
                - "/opt/bitnami/kafka/config/connect-distributed.properties"

              resources:
                requests:
                  cpu:    "100m"
                  memory: "256Mi"
                limits:
                  cpu:    "500m"
                  memory: "1Gi"

          volumes:
            - name: configuration
              configMap:
                name: kafka-connect-config

  # ────────────────────────────────────────────
  # 3) Service for Connect’s REST (port 8083)
  # ────────────────────────────────────────────
  - apiVersion: v1
    kind: Service
    metadata:
      name: kafka-connect
      labels:
        app.kubernetes.io/component: connector
    spec:
      type: ClusterIP
      ports:
        - protocol: TCP
          port: 8083
          targetPort: rest
          name: rest
      selector:
        app.kubernetes.io/component: connector

